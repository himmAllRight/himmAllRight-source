+++
title  = "TSQA 2020"
date   = "2020-04-18"
author = "Ryan Himmelwright"
image  = "img/posts/tsqa-2020/tsqa-2020-convention.jpeg"
caption = "TSQA 2020 - Durham Convention Center, Durham NC"
tags   = ["dev", "testing","events"]
draft  = "True"
Comments = "True"
+++

Several weeks ago, I attend TSQA 2020, the quality engineering conference presented every two years by the
[Triangle Software Quality Association](https://tsqa.org). Despite being hosted
by my local software testing group, the speakers were from all over. While only
a single-day conference, it was packed with all sorts of good advice and ideas
I left with. Here are my thoughts.

<!--more-->

## TSQA 2020

#### Getting There
TSQA was held at the [Durham Convention
Center](https://www.durhamconventioncenter.com) which is right in the middle of
downtown Durham (NC, USA). Being so close to the office, I managed to
convince/remind several of my co-workers to sign up. So, the morning of, I
drove the one mile to the office parking garage, and walked over to the
conference center.

As I walked inside, I immediately saw my manager at the entrance handing out
bandage (he was a volunteer for the conference) knew I was in the right place.
After saying hello and checking in, I made my way to the main ballroom to grab
some food. After awhile, my co-workers started trickling so we found a table
near the front and gathered for the Keynote.

#### Keynote

<center>
<a href="/img/posts/tsqa-2020/the_jetsons.jpg">
<img alt="The Jetsons" src="/img/posts/tsqa-2020/the_jetsons.jpg" style="max-width: 100%; padding: 5px 15px 10px 10px"/></a>
<div class="caption">The Jetsons</div>
</center>

They keynote, presented by [Angie Jones](http://angiejones.tech) was an
entertaining look at history and future of technology. She took ideas that were
shown in [The Jetsons](https://en.wikipedia.org/wiki/The_Jetsons), and compared
how close (or far) we have come to many of them. She then used this as an
example of how we should be planning to test *future* technology, because like
it or not, it's coming. She then concluded by providing some examples of what
testing of the future *could* look like.

#### Talks

The rest of the day, I sat in on several talks, interspaced with a lunch and
snack breaks. I mainly focused on attending talks around automation, but also
went to a few about developing test cases or UI testing tools. Similar to my
[All Things Open 2019 post](/post/ato2019/), instead of narrating each talk I
went to, I will pick out few lessons I learned and share them below.

After the conference ended, my co-workers and I made our way back to the office
so that we could share our experiences, and debate our thoughts over a drink.
It's always great to be able to hash out ideas with others after conference
while the ideas are still fresh. It was also fun :) .



### Lessons Learned/Strengthened

So, lets get to the summary of a few of the things I picked up while at TSQA
2020, that I want to implement more in my work daily.

#### No failing tests

It is all too easy to let a backlog of failing tests build up. This may be
due to the test being out of date, a low priority known issue, or worse of
all... just a flaky test. Regardless of the reason, failing tests really should
be mitigated *immediately*, for several reasons.

Leaving failing tests run causes failure fatigue. It allows failing tests
becomes normalized, and causes a team to ignore *other* failing tests in the
future. Basically, it decreases the competence in the test suite, and thus the
QA team as a whole.

<center>
<a href="/img/posts/tsqa-2020/disable-tests-meme.jpg">
<img alt="Failing tests meme" src="/img/posts/tsqa-2020/disable-tests-meme.jpg" style="max-width: 100%; padding: 5px 15px 10px 10px"/></a>
<div class="caption">This is supposed to be a joke, but it's actually
truthful. If tests are failing, disable or get rid of them, *AFTER* filing an
issue! </div>
</center>

So, if a test set has some continuously failing tests, try to fix them as quick
as possible. If there currently isn't time to fix it (we've all been there),
that is fine but file an issue to *remember* to fix it later, and disable it.
It will make a test suite *much* nicer to work with, because each failure
*means something important*.

One last statement here: **No** flaky tests either. If we can't depend on them,
they aren't worth having.  Either figure out how to fix them so they are
consistent, or remove them.

#### Automated Tests Ensure a know system *state*, not defects

Continuing from the advice to disable all continuously failing test, is the
idea that automated tests don't flag a *defects* in the system, but rather that
something has changed in the system's *state*.

Start thinking about automated tests as showing the 'state' of the system, and
failures indicate any deviation from that state. This might mean that I write a
test that shows a *known bug* is occuring. But that's fine, because we *know*
that bug happens, and if anything changes, we should know. When the bug is
fixed, we can update or remove that test. To take things a step further, when
we write the test, we should document it with a message like *"See Issue #XXXX.
Remove/update when that issue is resolved*" with a description on *why* the
test exists and *what* we expect to know about the state from it's results.

A passed or failed test is a data point, not a defect.

Example:

So on that note....


#### Better Documentation

<center>
<a href="/img/posts/tsqa-2020/documentation-meme.png">
<img alt="Documentation Meme" src="/img/posts/tsqa-2020/documentation-meme.png" style="max-width: 100%; padding: 5px 15px 10px 10px"/></a>
</center>

- We want to create context:
    - Why is a test passing, and what do we expect if it fails?
    - File defects in tickets and refer to them in the doc strings if needed.
    - Periodically check and clean up documentation. Don't have a bunch of
        useless TODOs everywhere.


#### Remember who's writting the tests
- Framework and tools
    - Need to be on the level of the people working with it and viewing the results
    - Itâ€™s valuable to align the automation with the language of the dev team code
    - Creating high level language that minimizes steps to write out cases
        - Good tool but not end state




## Conclusion

Overall, I think what I took away from the conference was a set of
different ways to look at everything in my role as a QE.


- It was a great conference
- Diverse

