+++
title  = "TSQA 2020"
date   = "2020-04-21"
author = "Ryan Himmelwright"
image  = "img/posts/tsqa-2020/tsqa-2020-convention.jpeg"
caption = "TSQA 2020 - Durham Convention Center, Durham NC"
tags   = ["dev", "testing","events"]
draft  = "True"
Comments = "True"
+++

Several weeks ago I attend TSQA 2020, a conference presented every two years by
the [Triangle Software Quality Association](https://tsqa.org) (TSQA). Despite
being hosted by my local software testing association, the speakers and
attendees were from all over the country. While only a single-day conference,
it was packed full with good advice and ideas I left with. Here are a few.

<!--more-->

*Just to clarify: TSQA occured in February, right before COVID-19 really started spreading
in the US. I'm just very late in this post.*

## TSQA 2020

#### Getting There

TSQA was held at the [Durham Convention
Center](https://www.durhamconventioncenter.com), which is located in the center
of downtown Durham (NC, USA). Being so close to our office, I managed to help
convince/remind several of my co-workers to register last minute. So on the
morning of the event, I drove the one mile to the office parking garage, and
hustled coat-less through the cold morning wind to the conference center.

As I walked inside, I immediately saw my manager at the entrance handing out
bandages and knew I was in the right place (he was a volunteer for the
conference).  After saying hello and checking in, I made my way to the main
ballroom to grab some food. After awhile, my co-workers started to trickle in,
so we found a table near the front and gathered for the opening statements.

#### Keynote

<center>
<a href="/img/posts/tsqa-2020/the_jetsons.jpg">
<img alt="The Jetsons" src="/img/posts/tsqa-2020/the_jetsons.jpg" style="max-width: 100%; padding: 5px 15px 10px 10px"/></a>
<div class="caption">The Jetsons</div>
</center>

They keynote, presented by [Angie Jones](http://angiejones.tech) was an
entertaining look at the history and future of technology. She took ideas that
were shown in [The Jetsons](https://en.wikipedia.org/wiki/The_Jetsons), and
compared them to how close (or far) we have come to many of them. She then used
this as an example of how we should be planning to test *future* technology,
because like it or not, it's coming. She concluded by providing some examples
of what testing of the future *could* look like.

#### Talks

The rest of the day, I attended several talks, interspaced with a lunch and
snack break. I mainly focused on attending talks around automation, but also
went to a few about developing test cases or UI testing tools. Similar to my
[All Things Open 2019 post](/post/ato2019/), instead of narrating each talk I
went to, I picked out few lessons I learned and will share them below.

After the conference ended, my co-workers and I made our way back to the office
to share our experiences, and debate our thoughts over a drink.
It's always great to hash out ideas with others after conference,
while they are still fresh. Also... it's fun :) .


### Lessons Learned/Strengthened

Now to summarize a few of the many lessons I picked up while at TSQA 2020. I've
heard many of these suggestions before, but the speakers presented them so well
at TSQA that they I really want to ensure I start implementing the at work.
Lets get started.

#### No failing tests

It is all too easy to let a backlog of failing tests build up. This may be
due to the test being out of date, a low priority issue, or worse of
all... just a flaky test. Regardless of the reason, failing tests really should
be mitigated *immediately*, for several reasons.

Leaving failing tests to continuously run causes failure fatigue. This
normalizes the failing tests and causes a team to ignore *other* failing tests in
the future. Basically, it decreases the competence in the test suite, and thus
the QA team as a whole.

<center>
<a href="/img/posts/tsqa-2020/disable-tests-meme.jpg">
<img alt="Failing tests meme" src="/img/posts/tsqa-2020/disable-tests-meme.jpg" style="max-width: 100%; padding: 5px 15px 10px 10px"/></a>
<div class="caption">This is supposed to be a joke, but it's actually
the point I'm sharing. If tests are failing, disable or get rid of them, *AFTER* filing an
issue! </div>
</center>

So, if a project has continuously failing tests, try to fix them as quick
as possible. If there currently isn't time to fix it (we've all been there),
that's fine, but file an issue to *remember* to fix it later. Then disable it.
It will make a test suite more meaningful, because each failure
*means something important*.

One last statement here: **No** flaky tests either. If we can't depend on them,
they aren't worth having.  Either figure out how to fix them so they are
consistent, or remove them.

#### Write tests to pass for known issues

Extending from the advice to disable all continuously failing tests, is the
idea to write tests that *pass* when a *known* defect happens. While sounding
counter-intuitive at first, this idea makes more sense when you consider that
automated tests don't find *defects*. Rather, automated tests asses the *state*
of a system, and fail when *something has changed*. So, a passed or failed test
acts as a *data point*. When a quality engineer goes and investigates the
test results, *they* determine if there is a defect, based on the data.

For example, lets assume I have a test that asserts that a particular api call
returns a `200` status, however due to a known issue, it is currently returning
`404`s. Because I *know* that the current state of the system is that the api
call returns `404`, I can change/add a test to assert that it is indeed,
returning `404`s. This technique *removes a failing test* (as suggest in the
previous section), while allowing us to maintain that data point. The test will
pass while it continues to return `404`'s, but will still fail and notify us of
any related state changes (i.e. the developers merge a bug fix... or a new
defect pops up resulting in the api call now returning `500` errors...).


#### Better Documentation

So... if we have our tests setup to pass for known defects, lets get one thing
clear... we need to make sure we have **amazing documentation**. This is
required.

<center>
<a href="/img/posts/tsqa-2020/documentation-meme.png">
<img alt="Documentation Meme" src="/img/posts/tsqa-2020/documentation-meme.png" style="max-width: 100%; padding: 5px 15px 10px 10px"/></a>
</center>

Lets continue with the example explained above. If I write a test to assert a
known defect is occurring, I should document in that test a few things:

- *Why the test is there*: If we have a test that is checking for "bad"
    behavior, it might be a good idea to quickly document in the test "Hey, we
    know this test is checking for something we don't want. It is just here
    until an issue is fixed".

- *The issue number*. If a test state exist until a known issue is resolved...
    please include the issue/bug number in the documentation. This will make it
    much easier for others (or you!) to find more information, ar check if the
    issue is closed once the test starts failing.

- *What we expect from the test*: Lastly, try to document why the test is
    currently passing, and what do we expect if it starts failing.

Continuing with out example from above:

>"This test has been altered until issue #23483 is resolved. Currently, this api
>call returns a 404 status. If the issue is resolved, it should return a 200
>status, at which point this test should be updated."

Remember to periodically clean up the documentation. One suggestion to help
keep track is when filing an issue, state were a failing test can be found if
it is being updated to match the behavior. This way when the issue is closed,
it will be easier to go update the test. Temporary test states can also be
marked with a tag, sudo as `TODO` to make them easier to search through.
Honestly whatever works. The goal is to create enough context so that someone
else is able to know what is going on and fix it without having to find you.


## Conclusion

Overall, TSQA 2020 turned out to be a great conference. It was great size for a
conference: not crazy and over-crowded, but not so small it felt awkward.
Additionally, it had a diverse mix of people that came from all over (actually,
I think it had the highest percentage of women I have ever seen at a tech
conference, bar far). I plan to definitely attend the next one... even if I
have to travel more than a mile next time.
