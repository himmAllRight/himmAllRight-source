+++
title  = "TSQA 2020"
date   = "2020-04-17"
author = "Ryan Himmelwright"
image  = "img/posts/tsqa-2020/tsqa-2020-convention.jpeg"
caption = "TSQA 2020 - Durham Convention Center, Durham NC"
tags   = ["dev", "testing","events"]
draft  = "False"
Comments = "True"
+++


<!--more-->

## TSQA 2020

- What it is, location, date, etc.
- Getting there, meeting up with co-workers
- Keynote

- It was a great conference
- Diverse

- Brief summary about the types of talks I went to

### Learning Points/Take-aways/some things to work on


#### No failing tests
Start thinking about automated tests as showing the 'state' of the
system, and failures indicate any deviation from that state. This
might mean that I write a test that shows a *known bug* is
occuring. But that's fine, because we *know* that bug happens, and if
anything changes, we should know. When the bug is fixed, we can update
or remove that test. To take things a step further, when we write the
test, we should document it with a message like *"See Issue
#XXXX. Remove/update when that issue is resolved*" with a description on *why* the test exists and *what* we expect to know about the state from it's results.

A passed or failed test is a data point, not a defect.

So on that note....

#### Better Documentation

*<< Insert meme about development documentation?? >>*


#### Remember who's writting the tests
- Framework and tools
    - Need to be on the level of the people working with it and viewing the results
    - Itâ€™s valuable to align the automation with the language of the dev team code
    - Creating high level language that minimizes steps to write out cases
        - Good tool but not end state

### Using Score cards/prioritizing what to automate


#### Look into BDD?


## Conclusion

Overall, I think what I took away from the conference was a set of
different ways to look at everything in my role as a QE.
